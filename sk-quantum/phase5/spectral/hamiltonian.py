"""
Hamiltonian from Computation Graph
==================================

Phase 5: ãƒãƒŸãƒ«ãƒˆãƒ‹ã‚¢ãƒ³ã¨å¹²æ¸‰

ç›®çš„:
    è¨ˆç®—ã‚°ãƒ©ãƒ•ã®éš£æ¥è¡Œåˆ—ã‚’ãƒãƒŸãƒ«ãƒˆãƒ‹ã‚¢ãƒ³ã¨ã—ã¦å®šç¾©ã—ã€
    é€£ç¶šæ™‚é–“ç™ºå±•ã«ã‚ˆã‚‹å¹²æ¸‰ã®æœ‰ç„¡ã‚’æ¤œè¨¼ã™ã‚‹ã€‚

ç†è«–çš„èƒŒæ™¯:
    é›¢æ•£è¨ˆç®—ï¼ˆç½®æ›è¡Œåˆ—ï¼‰ã§ã¯è¤‡ç´ æ§‹é€ ãŒç”Ÿã˜ãªã„ï¼ˆPhase 4ã§ç¢ºèªï¼‰ã€‚
    ã—ã‹ã—ã€é€£ç¶šæ™‚é–“åŒ– U(t) = exp(-iHt) ã§ã¯è¤‡ç´ æŒ‡æ•°é–¢æ•°ãŒç¾ã‚Œã€
    å¹²æ¸‰ãŒç”Ÿã˜ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã€‚

    ã“ã‚Œã¯é€£ç¶šæ™‚é–“é‡å­ã‚¦ã‚©ãƒ¼ã‚¯ï¼ˆCTQWï¼‰ã¨åŒã˜æ§‹é€ ï¼š
    - H = Aï¼ˆéš£æ¥è¡Œåˆ—ï¼‰ã¾ãŸã¯ H = Lï¼ˆãƒ©ãƒ—ãƒ©ã‚·ã‚¢ãƒ³ï¼‰
    - åˆæœŸçŠ¶æ…‹ |Ïˆ(0)âŸ© ã‹ã‚‰æ™‚é–“ç™ºå±• |Ïˆ(t)âŸ© = exp(-iHt)|Ïˆ(0)âŸ©
    - å¹²æ¸‰ãƒ‘ã‚¿ãƒ¼ãƒ³ãŒè¦³æ¸¬ã•ã‚Œã‚Œã°ã€Œé‡å­çš„ã€
"""

from __future__ import annotations
import sys
import os
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', '..', 'phase0'))

from dataclasses import dataclass, field
from typing import List, Dict, Set, Tuple, Optional
import numpy as np
from numpy.linalg import eig, eigvals
from scipy.linalg import expm

from sk_parser import SKExpr, parse, to_string, to_canonical
from multiway import MultiwayGraph, build_multiway_graph, MultiwayNode


# =============================================================================
# Adjacency Matrix Construction
# =============================================================================

@dataclass
class ComputationHamiltonian:
    """
    è¨ˆç®—ã‚°ãƒ©ãƒ•ã‹ã‚‰ãƒãƒŸãƒ«ãƒˆãƒ‹ã‚¢ãƒ³ï¼ˆéš£æ¥è¡Œåˆ—ï¼‰ã‚’æ§‹ç¯‰
    """
    graph: MultiwayGraph
    nodes: List[MultiwayNode] = field(default_factory=list, init=False)
    node_to_idx: Dict[str, int] = field(default_factory=dict, init=False)
    adjacency: np.ndarray = field(default=None, init=False)
    laplacian: np.ndarray = field(default=None, init=False)
    
    def __post_init__(self):
        self._build_matrices()
    
    def _build_matrices(self):
        """éš£æ¥è¡Œåˆ—ã¨ãƒ©ãƒ—ãƒ©ã‚·ã‚¢ãƒ³ã‚’æ§‹ç¯‰"""
        # ãƒãƒ¼ãƒ‰ã®ãƒªã‚¹ãƒˆåŒ–
        self.nodes = list(self.graph.nodes.values())
        self.node_to_idx = {node.node_id: i for i, node in enumerate(self.nodes)}
        
        n = len(self.nodes)
        self.adjacency = np.zeros((n, n), dtype=np.float64)
        
        # è¾ºã‚’è¿½åŠ ï¼ˆå„ãƒãƒ¼ãƒ‰ã® children ã‹ã‚‰ï¼‰
        for node in self.nodes:
            i = self.node_to_idx[node.node_id]
            for child in node.children.values():
                j = self.node_to_idx[child.node_id]
                self.adjacency[i, j] = 1.0
                self.adjacency[j, i] = 1.0  # ç„¡å‘åŒ–
        
        # ãƒ©ãƒ—ãƒ©ã‚·ã‚¢ãƒ³ L = D - A
        degree = np.diag(self.adjacency.sum(axis=1))
        self.laplacian = degree - self.adjacency
    
    @property
    def dimension(self) -> int:
        """ãƒ’ãƒ«ãƒ™ãƒ«ãƒˆç©ºé–“ã®æ¬¡å…ƒ"""
        return len(self.nodes)
    
    def get_hamiltonian(self, type: str = 'adjacency') -> np.ndarray:
        """
        ãƒãƒŸãƒ«ãƒˆãƒ‹ã‚¢ãƒ³ã‚’å–å¾—
        
        Args:
            type: 'adjacency' or 'laplacian'
        """
        if type == 'adjacency':
            return self.adjacency
        elif type == 'laplacian':
            return self.laplacian
        else:
            raise ValueError(f"Unknown type: {type}")
    
    def get_node_label(self, idx: int) -> str:
        """ãƒãƒ¼ãƒ‰ã®ãƒ©ãƒ™ãƒ«ï¼ˆå¼ã®æ–‡å­—åˆ—è¡¨ç¾ï¼‰"""
        return to_string(self.nodes[idx].expr)


# =============================================================================
# Spectral Analysis
# =============================================================================

@dataclass
class SpectralAnalysis:
    """
    ãƒãƒŸãƒ«ãƒˆãƒ‹ã‚¢ãƒ³ã®ã‚¹ãƒšã‚¯ãƒˆãƒ«è§£æ
    """
    hamiltonian: np.ndarray
    eigenvalues: np.ndarray = field(default=None, init=False)
    eigenvectors: np.ndarray = field(default=None, init=False)
    
    def __post_init__(self):
        self._compute_spectrum()
    
    def _compute_spectrum(self):
        """å›ºæœ‰å€¤ãƒ»å›ºæœ‰ãƒ™ã‚¯ãƒˆãƒ«ã‚’è¨ˆç®—"""
        self.eigenvalues, self.eigenvectors = eig(self.hamiltonian)
        # å®Ÿå¯¾ç§°è¡Œåˆ—ãªã®ã§å›ºæœ‰å€¤ã¯å®Ÿæ•°ã®ã¯ãš
        if np.allclose(self.eigenvalues.imag, 0):
            self.eigenvalues = self.eigenvalues.real
        # å›ºæœ‰å€¤ã§ã‚½ãƒ¼ãƒˆ
        idx = np.argsort(self.eigenvalues)
        self.eigenvalues = self.eigenvalues[idx]
        self.eigenvectors = self.eigenvectors[:, idx]
    
    @property
    def spectral_gap(self) -> float:
        """ã‚¹ãƒšã‚¯ãƒˆãƒ«ã‚®ãƒ£ãƒƒãƒ—ï¼ˆæœ€å°éã‚¼ãƒ­å›ºæœ‰å€¤ï¼‰"""
        nonzero = self.eigenvalues[np.abs(self.eigenvalues) > 1e-10]
        if len(nonzero) == 0:
            return 0.0
        return np.min(np.abs(nonzero))
    
    @property
    def bandwidth(self) -> float:
        """å¸¯åŸŸå¹…ï¼ˆæœ€å¤§å›ºæœ‰å€¤ - æœ€å°å›ºæœ‰å€¤ï¼‰"""
        return np.max(self.eigenvalues) - np.min(self.eigenvalues)
    
    def analyze(self) -> Dict:
        """ã‚¹ãƒšã‚¯ãƒˆãƒ«ã®è©³ç´°è§£æ"""
        return {
            'dimension': len(self.eigenvalues),
            'eigenvalues': self.eigenvalues,
            'min_eigenvalue': np.min(self.eigenvalues),
            'max_eigenvalue': np.max(self.eigenvalues),
            'spectral_gap': self.spectral_gap,
            'bandwidth': self.bandwidth,
            'all_real': np.allclose(self.eigenvalues.imag, 0) if np.iscomplexobj(self.eigenvalues) else True,
            'degeneracy': self._count_degeneracy(),
        }
    
    def _count_degeneracy(self, tol: float = 1e-8) -> Dict[float, int]:
        """å›ºæœ‰å€¤ã®ç¸®é€€åº¦ã‚’è¨ˆç®—"""
        unique, counts = np.unique(np.round(self.eigenvalues.real, 8), return_counts=True)
        return {float(v): int(c) for v, c in zip(unique, counts) if c > 1}


# =============================================================================
# Quantum Walk
# =============================================================================

@dataclass
class ContinuousTimeQuantumWalk:
    """
    é€£ç¶šæ™‚é–“é‡å­ã‚¦ã‚©ãƒ¼ã‚¯
    
    |Ïˆ(t)âŸ© = exp(-iHt)|Ïˆ(0)âŸ©
    
    H ã¯éš£æ¥è¡Œåˆ—ã¾ãŸã¯ãƒ©ãƒ—ãƒ©ã‚·ã‚¢ãƒ³
    """
    hamiltonian: np.ndarray
    
    def evolve(self, initial_state: np.ndarray, t: float) -> np.ndarray:
        """
        æ™‚é–“ç™ºå±•
        
        Args:
            initial_state: åˆæœŸçŠ¶æ…‹ãƒ™ã‚¯ãƒˆãƒ« |Ïˆ(0)âŸ©
            t: æ™‚é–“
        
        Returns:
            |Ïˆ(t)âŸ© = exp(-iHt)|Ïˆ(0)âŸ©
        """
        U = expm(-1j * self.hamiltonian * t)
        return U @ initial_state
    
    def probability_distribution(self, initial_state: np.ndarray, t: float) -> np.ndarray:
        """
        ç¢ºç‡åˆ†å¸ƒ |Ïˆ(t)|Â²
        """
        psi_t = self.evolve(initial_state, t)
        return np.abs(psi_t) ** 2
    
    def evolution_operator(self, t: float) -> np.ndarray:
        """
        æ™‚é–“ç™ºå±•æ¼”ç®—å­ U(t) = exp(-iHt)
        """
        return expm(-1j * self.hamiltonian * t)
    
    def is_unitary(self, t: float, tol: float = 1e-10) -> bool:
        """U(t) ãŒãƒ¦ãƒ‹ã‚¿ãƒªã‹ã©ã†ã‹"""
        U = self.evolution_operator(t)
        I = np.eye(len(U))
        return np.allclose(U @ U.conj().T, I, atol=tol)


# =============================================================================
# Classical Random Walk (for comparison)
# =============================================================================

@dataclass
class ClassicalRandomWalk:
    """
    å¤å…¸ãƒ©ãƒ³ãƒ€ãƒ ã‚¦ã‚©ãƒ¼ã‚¯ï¼ˆæ¯”è¼ƒç”¨ï¼‰
    
    é·ç§»ç¢ºç‡è¡Œåˆ— P = D^{-1} A
    """
    adjacency: np.ndarray
    transition: np.ndarray = field(default=None, init=False)
    
    def __post_init__(self):
        degree = self.adjacency.sum(axis=1)
        # ã‚¼ãƒ­é™¤ç®—ã‚’é¿ã‘ã‚‹
        degree[degree == 0] = 1
        self.transition = self.adjacency / degree[:, np.newaxis]
    
    def step(self, distribution: np.ndarray) -> np.ndarray:
        """
        1ã‚¹ãƒ†ãƒƒãƒ—ã®é·ç§»
        
        p(t+1) = P^T p(t)
        """
        return self.transition.T @ distribution
    
    def evolve(self, initial: np.ndarray, steps: int) -> np.ndarray:
        """
        è¤‡æ•°ã‚¹ãƒ†ãƒƒãƒ—ã®é·ç§»
        """
        p = initial.copy()
        for _ in range(steps):
            p = self.step(p)
        return p
    
    def stationary_distribution(self) -> np.ndarray:
        """
        å®šå¸¸åˆ†å¸ƒï¼ˆä¸»å›ºæœ‰ãƒ™ã‚¯ãƒˆãƒ«ï¼‰
        """
        eigenvalues, eigenvectors = eig(self.transition.T)
        # å›ºæœ‰å€¤1ã«å¯¾å¿œã™ã‚‹å›ºæœ‰ãƒ™ã‚¯ãƒˆãƒ«
        idx = np.argmin(np.abs(eigenvalues - 1))
        stationary = eigenvectors[:, idx].real
        return stationary / stationary.sum()


# =============================================================================
# Interference Detection
# =============================================================================

@dataclass
class InterferenceAnalysis:
    """
    å¹²æ¸‰ã®æ¤œå‡ºã¨è§£æ
    """
    quantum_walk: ContinuousTimeQuantumWalk
    classical_walk: ClassicalRandomWalk
    dimension: int
    
    def compare_distributions(self, initial_idx: int, t: float, 
                              classical_steps: int = None) -> Dict:
        """
        é‡å­ã‚¦ã‚©ãƒ¼ã‚¯ã¨å¤å…¸ã‚¦ã‚©ãƒ¼ã‚¯ã®åˆ†å¸ƒã‚’æ¯”è¼ƒ
        
        Args:
            initial_idx: åˆæœŸçŠ¶æ…‹ã®ãƒãƒ¼ãƒ‰ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
            t: é‡å­ã‚¦ã‚©ãƒ¼ã‚¯ã®æ™‚é–“
            classical_steps: å¤å…¸ã‚¦ã‚©ãƒ¼ã‚¯ã®ã‚¹ãƒ†ãƒƒãƒ—æ•°ï¼ˆNone ãªã‚‰ t ã‚’ä½¿ç”¨ï¼‰
        """
        # åˆæœŸçŠ¶æ…‹
        initial = np.zeros(self.dimension)
        initial[initial_idx] = 1.0
        
        # é‡å­ã‚¦ã‚©ãƒ¼ã‚¯
        quantum_prob = self.quantum_walk.probability_distribution(initial, t)
        
        # å¤å…¸ã‚¦ã‚©ãƒ¼ã‚¯
        if classical_steps is None:
            classical_steps = int(t)
        classical_prob = self.classical_walk.evolve(initial, max(1, classical_steps))
        
        # æ¯”è¼ƒæŒ‡æ¨™
        return {
            'quantum_prob': quantum_prob,
            'classical_prob': classical_prob,
            'total_variation': 0.5 * np.sum(np.abs(quantum_prob - classical_prob)),
            'quantum_entropy': self._entropy(quantum_prob),
            'classical_entropy': self._entropy(classical_prob),
            'max_quantum_prob': np.max(quantum_prob),
            'max_classical_prob': np.max(classical_prob),
        }
    
    def _entropy(self, prob: np.ndarray) -> float:
        """Shannon ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼"""
        p = prob[prob > 1e-15]
        return -np.sum(p * np.log2(p))
    
    def detect_interference(self, initial_idx: int, times: List[float]) -> Dict:
        """
        å¹²æ¸‰ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œå‡º
        
        é‡å­ã‚¦ã‚©ãƒ¼ã‚¯ã§ã¯ç¢ºç‡ãŒæ™‚é–“ã«å¯¾ã—ã¦æŒ¯å‹•ã™ã‚‹ãŒã€
        å¤å…¸ã‚¦ã‚©ãƒ¼ã‚¯ã§ã¯å˜èª¿ã«å®šå¸¸åˆ†å¸ƒã«è¿‘ã¥ãã€‚
        """
        initial = np.zeros(self.dimension)
        initial[initial_idx] = 1.0
        
        quantum_probs = []
        for t in times:
            prob = self.quantum_walk.probability_distribution(initial, t)
            quantum_probs.append(prob)
        
        quantum_probs = np.array(quantum_probs)
        
        # æ™‚é–“æ–¹å‘ã®æŒ¯å‹•ã‚’æ¤œå‡º
        oscillation = np.std(quantum_probs, axis=0)
        
        return {
            'times': times,
            'quantum_probs': quantum_probs,
            'oscillation_per_node': oscillation,
            'mean_oscillation': np.mean(oscillation),
            'has_interference': np.mean(oscillation) > 0.01,
        }


# =============================================================================
# Main Analysis Functions
# =============================================================================

def build_hamiltonian_from_expression(expr_str: str, max_depth: int = 20) -> ComputationHamiltonian:
    """
    SKå¼ã‹ã‚‰è¨ˆç®—ã‚°ãƒ©ãƒ•ã‚’æ§‹ç¯‰ã—ã€ãƒãƒŸãƒ«ãƒˆãƒ‹ã‚¢ãƒ³ã‚’ç”Ÿæˆ
    """
    expr = parse(expr_str)
    graph = build_multiway_graph(expr, max_depth=max_depth)
    return ComputationHamiltonian(graph)


def analyze_expression(expr_str: str, max_depth: int = 20, verbose: bool = True) -> Dict:
    """
    SKå¼ã®å®Œå…¨ãªè§£æï¼ˆã‚¹ãƒšã‚¯ãƒˆãƒ« + é‡å­ã‚¦ã‚©ãƒ¼ã‚¯ï¼‰
    """
    results = {'expression': expr_str}
    
    if verbose:
        print(f"\n{'='*70}")
        print(f"è§£æ: {expr_str}")
        print(f"{'='*70}")
    
    # ãƒãƒŸãƒ«ãƒˆãƒ‹ã‚¢ãƒ³æ§‹ç¯‰
    H = build_hamiltonian_from_expression(expr_str, max_depth)
    results['dimension'] = H.dimension
    results['n_nodes'] = len(H.nodes)
    
    # è¾ºæ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆï¼ˆéš£æ¥è¡Œåˆ—ã‹ã‚‰ï¼‰
    n_edges = int(H.adjacency.sum() / 2)  # ç„¡å‘ã‚°ãƒ©ãƒ•ãªã®ã§2ã§å‰²ã‚‹
    results['n_edges'] = n_edges
    
    if verbose:
        print(f"\nã‚°ãƒ©ãƒ•æ§‹é€ :")
        print(f"  ãƒãƒ¼ãƒ‰æ•°: {H.dimension}")
        print(f"  è¾ºæ•°: {n_edges}")
    
    if H.dimension < 2:
        if verbose:
            print("  âš ï¸ ã‚°ãƒ©ãƒ•ãŒå°ã•ã™ãã¾ã™ï¼ˆãƒãƒ¼ãƒ‰æ•° < 2ï¼‰")
        results['error'] = 'Graph too small'
        return results
    
    # ã‚¹ãƒšã‚¯ãƒˆãƒ«è§£æ
    adj = H.get_hamiltonian('adjacency')
    spectral = SpectralAnalysis(adj)
    spec_results = spectral.analyze()
    results['spectral'] = spec_results
    
    if verbose:
        print(f"\nã‚¹ãƒšã‚¯ãƒˆãƒ«è§£æ:")
        print(f"  å›ºæœ‰å€¤ç¯„å›²: [{spec_results['min_eigenvalue']:.4f}, {spec_results['max_eigenvalue']:.4f}]")
        print(f"  ã‚¹ãƒšã‚¯ãƒˆãƒ«ã‚®ãƒ£ãƒƒãƒ—: {spec_results['spectral_gap']:.4f}")
        print(f"  å¸¯åŸŸå¹…: {spec_results['bandwidth']:.4f}")
        if spec_results['degeneracy']:
            print(f"  ç¸®é€€: {spec_results['degeneracy']}")
    
    # é‡å­ã‚¦ã‚©ãƒ¼ã‚¯
    qw = ContinuousTimeQuantumWalk(adj)
    cw = ClassicalRandomWalk(adj)
    
    # ãƒ¦ãƒ‹ã‚¿ãƒªæ€§ã®æ¤œè¨¼
    is_unitary = qw.is_unitary(1.0)
    results['is_unitary'] = is_unitary
    
    if verbose:
        print(f"\né‡å­ã‚¦ã‚©ãƒ¼ã‚¯:")
        print(f"  U(t=1) ã¯ãƒ¦ãƒ‹ã‚¿ãƒª: {is_unitary}")
    
    # å¹²æ¸‰è§£æ
    interference = InterferenceAnalysis(qw, cw, H.dimension)
    times = np.linspace(0.1, 10, 50)
    int_results = interference.detect_interference(0, times)
    results['interference'] = {
        'has_interference': int_results['has_interference'],
        'mean_oscillation': int_results['mean_oscillation'],
    }
    
    if verbose:
        print(f"  å¹³å‡æŒ¯å‹•: {int_results['mean_oscillation']:.4f}")
        print(f"  å¹²æ¸‰ã‚ã‚Š: {int_results['has_interference']}")
    
    # é‡å­ vs å¤å…¸ã®æ¯”è¼ƒ
    comparison = interference.compare_distributions(0, 5.0, 5)
    results['quantum_vs_classical'] = {
        'total_variation': comparison['total_variation'],
        'quantum_entropy': comparison['quantum_entropy'],
        'classical_entropy': comparison['classical_entropy'],
    }
    
    if verbose:
        print(f"\né‡å­ vs å¤å…¸ (t=5):")
        print(f"  Total Variation: {comparison['total_variation']:.4f}")
        print(f"  é‡å­ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼: {comparison['quantum_entropy']:.4f}")
        print(f"  å¤å…¸ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼: {comparison['classical_entropy']:.4f}")
    
    return results


def run_phase5_analysis(verbose: bool = True) -> Dict:
    """
    Phase 5 ã®å®Œå…¨ãªè§£æã‚’å®Ÿè¡Œ
    """
    results = {}
    
    if verbose:
        print("=" * 70)
        print("Phase 5: ãƒãƒŸãƒ«ãƒˆãƒ‹ã‚¢ãƒ³ã¨å¹²æ¸‰")
        print("=" * 70)
        print("\nç›®çš„: é€£ç¶šæ™‚é–“é‡å­ã‚¦ã‚©ãƒ¼ã‚¯ã§å¹²æ¸‰ãŒç”Ÿã˜ã‚‹ã‹ã‚’æ¤œè¨¼")
        print("ç†è«–: U(t) = exp(-iAt) ã¯è¤‡ç´ æ•°ã‚’å°å…¥ã—ã€å¹²æ¸‰ã‚’ç”Ÿã˜ã•ã›ã‚‹å¯èƒ½æ€§")
    
    # ãƒ†ã‚¹ãƒˆå¼
    test_expressions = [
        "S (K a) (K b) c",
        "(K a b) (K c d)",
        "(K a b) (K c d) (K e f)",
        "S (K a) (K b) (S c d e)",
    ]
    
    for expr_str in test_expressions:
        results[expr_str] = analyze_expression(expr_str, verbose=verbose)
    
    # çµè«–
    if verbose:
        print("\n" + "=" * 70)
        print("Phase 5: çµè«–")
        print("=" * 70)
        
        any_interference = any(
            r.get('interference', {}).get('has_interference', False)
            for r in results.values()
        )
        
        if any_interference:
            print("\n  ğŸ”” å¹²æ¸‰ãƒ‘ã‚¿ãƒ¼ãƒ³ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸï¼")
            print("     é€£ç¶šæ™‚é–“é‡å­ã‚¦ã‚©ãƒ¼ã‚¯ã§ã¯ã€é›¢æ•£è¨ˆç®—ã¨ç•°ãªã‚‹æŒ¯ã‚‹èˆã„ãŒç”Ÿã˜ã¾ã™ã€‚")
        else:
            print("\n  âœ“ å¹²æ¸‰ãƒ‘ã‚¿ãƒ¼ãƒ³ã¯æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚")
            print("     ã—ã‹ã—ã€ã“ã‚Œã¯è¨ˆç®—ã‚°ãƒ©ãƒ•ã®æ§‹é€ ã«ä¾å­˜ã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")
        
        print("\n  ç†è«–çš„è€ƒå¯Ÿ:")
        print("    - éš£æ¥è¡Œåˆ— A ã¯å®Ÿå¯¾ç§°è¡Œåˆ— â†’ å›ºæœ‰å€¤ã¯å®Ÿæ•°")
        print("    - U(t) = exp(-iAt) ã¯è¤‡ç´ è¡Œåˆ— â†’ ãƒ¦ãƒ‹ã‚¿ãƒª")
        print("    - è¤‡ç´ æ§‹é€ ã¯ã€Œé€£ç¶šæ™‚é–“åŒ–ã€ã«ã‚ˆã£ã¦å°å…¥ã•ã‚Œã‚‹")
        print("    - ã“ã‚Œã¯ã€Œé›¢æ•£â†’é€£ç¶šã€ã®æ¥µé™ã§é‡å­æ€§ãŒç¾ã‚Œã‚‹ã“ã¨ã‚’ç¤ºå”†")
    
    return results


# =============================================================================
# Main
# =============================================================================

if __name__ == "__main__":
    results = run_phase5_analysis(verbose=True)

